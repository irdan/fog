{
    "body": "{\n    \"values\": [\n        {\n            \"id\": \"remote.http_body_match_1\",\n            \"label\": \"Body match - string found\",\n            \"description\": \"Alarm which returns CRITICAL if the provided string is found in the body\",\n            \"check_type\": \"remote.http\",\n            \"criteria\": \"if (metric['body_match'] regex '${string}') {\\n  return new AlarmStatus(CRITICAL, '${string} found, returning CRITICAL.');\\n}\\n\",\n            \"fields\": [\n                {\n                    \"name\": \"string\",\n                    \"description\": \"String to check for in the body\",\n                    \"type\": \"string\"\n                }\n            ]\n        },\n        {\n            \"id\": \"remote.http_body_match_missing_string\",\n            \"label\": \"Body match - string not found\",\n            \"description\": \"Alarm which returns CRITICAL if the provided string is not found in the body\",\n            \"check_type\": \"remote.http\",\n            \"criteria\": \"if (metric['body_match'] == '') {\\n  return new AlarmStatus(CRITICAL, 'HTTP response did not contain the correct content.');\\n}\\n\\nreturn new AlarmStatus(OK, 'HTTP response contains the correct content');\\n\",\n            \"fields\": []\n        },\n        {\n            \"id\": \"remote.http_connection_time\",\n            \"label\": \"Connection time\",\n            \"description\": \"Alarm which returns WARNING or CRITICAL based on the connection time\",\n            \"check_type\": \"remote.http\",\n            \"criteria\": \"if (metric['duration'] > ${critical_threshold}) {\\n  return new AlarmStatus(CRITICAL, 'HTTP request took more than ${critical_threshold} milliseconds.');\\n}\\n\\nif (metric['duration'] > ${warning_threshold}) {\\n  return new AlarmStatus(WARNING, 'HTTP request took more than ${warning_threshold} milliseconds.');\\n}\\n\\nreturn new AlarmStatus(OK, 'HTTP connection time is normal');\\n\",\n            \"fields\": [\n                {\n                    \"name\": \"warning_threshold\",\n                    \"description\": \"Warning threshold (in milliseconds) for the connection time\",\n                    \"type\": \"integer\"\n                },\n                {\n                    \"name\": \"critical_threshold\",\n                    \"description\": \"Critical threshold (in milliseconds) for the connection time\",\n                    \"type\": \"integer\"\n                }\n            ]\n        },\n        {\n            \"id\": \"remote.http_status_code\",\n            \"label\": \"Status code\",\n            \"description\": \"Alarm which returns WARNING if the server responses with 4xx status code or CRITICAL if it responds with 5xx status code\",\n            \"check_type\": \"remote.http\",\n            \"criteria\": \"if (metric['code'] regex '4[0-9][0-9]') {\\n  return new AlarmStatus(CRITICAL, 'HTTP server responding with 4xx status');\\n}\\n\\nif (metric['code'] regex '5[0-9][0-9]') {\\n  return new AlarmStatus(CRITICAL, 'HTTP server responding with 5xx status');\\n}\\n\\nreturn new AlarmStatus(OK, 'HTTP server is functioning normally');\\n\",\n            \"fields\": []\n        },\n        {\n            \"id\": \"remote.http_cert_expiration\",\n            \"label\": \"SSL certificate expiration time\",\n            \"description\": \"Alarm which returns WARNING or CRITICAL based on the certificate expiration date\",\n            \"check_type\": \"remote.http\",\n            \"criteria\": \"if (metric['cert_end_in'] < ${critical_threshold}) {\\n  return new AlarmStatus(CRITICAL, 'Cert expiring in less than ${critical_threshold} seconds.');\\n}\\n\\nif (metric['cert_end_in'] < ${warning_threshold}) {\\n  return new AlarmStatus(WARNING, 'Cert expiring in less than ${warning_threshold} seconds.');\\n}\\n\\nreturn new AlarmStatus(OK, 'HTTP certificate doesn\\\\'t expire soon.');\\n\",\n            \"fields\": [\n                {\n                    \"name\": \"warning_threshold\",\n                    \"description\": \"Warning threshold (in seconds) for the certificate expiration\",\n                    \"type\": \"integer\"\n                },\n                {\n                    \"name\": \"critical_threshold\",\n                    \"description\": \"Critical threshold (in seconds) for the certificate expiration\",\n                    \"type\": \"integer\"\n                }\n            ]\n        },\n        {\n            \"id\": \"remote.dns_address_match\",\n            \"label\": \"DNS record address match\",\n            \"description\": \"Alarm which returns CRITICAL if the DNS record is not resolved to the provided address\",\n            \"check_type\": \"remote.dns\",\n            \"criteria\": \"# Match if the 127... address was in the resolution\\n# if it wasn't than default to CRITICAL\\n\\nif (metric['answer'] regex '.*${address}.*') {\\n  return new AlarmStatus(OK, 'Resolved the correct address!');\\n}\\nreturn new AlarmStatus(CRITICAL);\\n\",\n            \"fields\": [\n                {\n                    \"name\": \"address\",\n                    \"description\": \"Address to which the DNS record must resolve to\",\n                    \"type\": \"string\"\n                }\n            ]\n        },\n        {\n            \"id\": \"remote.ssh_banner_match\",\n            \"label\": \"SSH banner match\",\n            \"description\": \"Alarm which returns CRITICAL if the service listening on SSH port doesn't return a valid banner\",\n            \"check_type\": \"remote.ssh\",\n            \"criteria\": \"/* Have the check match at the edge */\\nif (metric['banner_matched'] != '') {\\n  return new AlarmStatus(OK);\\n}\\n\\n/* Or use the regex parser in the\\n   language to build multiple matches\\n   in a single alarm. */\\nif (metric['banner'] regex 'OpenSSH.*') {\\n  return new AlarmStatus(OK);\\n}\\n\\nreturn new AlarmStatus(CRITICAL, 'Match not found.');\\n\",\n            \"fields\": []\n        },\n        {\n            \"id\": \"remote.ssh_fingerprint_match\",\n            \"label\": \"SSH fingerprint match\",\n            \"description\": \"Alarm which returns CRITICAL if the SSH fingerprint doesn't match the provided one\",\n            \"check_type\": \"remote.ssh\",\n            \"criteria\": \"if (metric['fingerprint'] != '${fingerprint}') {\\n  return new AlarmStatus(CRITICAL, 'SSH fingerprint didn\\\\'t match the expected one ${fingerprint}');\\n}\\n\\nreturn new AlarmStatus(OK, 'Got expected SSH fingerprint (${fingerprint})');\\n\",\n            \"fields\": [\n                {\n                    \"name\": \"fingerprint\",\n                    \"description\": \"Expected SSH fingerprint\",\n                    \"type\": \"string\"\n                }\n            ]\n        },\n        {\n            \"id\": \"remote.ping_packet_loss\",\n            \"label\": \"Ping packet loss\",\n            \"description\": \"Alarm which returns WARNING if the packet loss is greater than 5% and CRITICAL if it's greater than 20%\",\n            \"check_type\": \"remote.ping\",\n            \"criteria\": \"if (metric['available'] < 80) {\\n  return new AlarmStatus(CRITICAL, 'Packet loss is greater than 20%');\\n}\\n\\nif (metric['available'] < 95) {\\n  return new AlarmStatus(WARNING, 'Packet loss is greater than 5%');\\n}\\n\\nreturn new AlarmStatus(OK, 'Packet loss is normal');\\n\",\n            \"fields\": []\n        },\n        {\n            \"id\": \"remote.tcp_connection_time\",\n            \"label\": \"Connection time\",\n            \"description\": \"Alarm which returns WARNING or CRITICAL based on the connection time\",\n            \"check_type\": \"remote.tcp\",\n            \"criteria\": \"if (metric['duration'] > ${critical_threshold}) {\\n  return new AlarmStatus(CRITICAL, 'TCP Connection took more than ${critical_threshold} milliseconds.');\\n}\\n\\nif (metric['duration'] > ${warning_threshold}) {\\n  return new AlarmStatus(WARNING, 'TCP Connection took more than ${warning_threshold} milliseconds.');\\n}\\n\\nreturn new AlarmStatus(OK, 'TCP connection time is normal');\\n\",\n            \"fields\": [\n                {\n                    \"name\": \"warning_threshold\",\n                    \"description\": \"Warning threshold (in seconds) for the connection time\",\n                    \"type\": \"integer\"\n                },\n                {\n                    \"name\": \"critical_threshold\",\n                    \"description\": \"Critical threshold (in seconds) for the connection time\",\n                    \"type\": \"integer\"\n                }\n            ]\n        },\n        {\n            \"id\": \"remote.dns_spf_record_include_match\",\n            \"label\": \"SPF TXT record\",\n            \"description\": \"Alarm which returns CRITICAL if the SPF record doesn't contain an include clause with the provided domain.\",\n            \"check_type\": \"remote.dns\",\n            \"criteria\": \"if (metric['answer'] regex 'v=spf1.* include:${domain} .*[~|-]all') {\\n  return new AlarmStatus(OK, 'SPF record with include clause for domain ${domain} exists');\\n}\\n\\nreturn new AlarmStatus(CRITICAL, 'SPF record doesn\\\\'t contain an include clause for domain ${domain}');\\n\",\n            \"fields\": [\n                {\n                    \"name\": \"domain\",\n                    \"description\": \"Domain to check for\",\n                    \"type\": \"string\"\n                }\n            ]\n        },\n        {\n            \"id\": \"remote.dns_dkim_public_key_match\",\n            \"label\": \"DKIM TXT record\",\n            \"description\": \"Alarm which returns CRITICAL if the DKIM record doesn't contain or match the provided public key.\",\n            \"check_type\": \"remote.dns\",\n            \"criteria\": \"if (metric['answer'] regex '.*p=${public_key}$') {\\n  return new AlarmStatus(OK, 'DKIM record contains a provided public key');\\n}\\n\\nreturn new AlarmStatus(CRITICAL, 'DKIM record doesn\\\\'t contain a provided public key');\\n\",\n            \"fields\": [\n                {\n                    \"name\": \"public_key\",\n                    \"description\": \"Public key to check for. Note: Special characters must be escaped.\",\n                    \"type\": \"string\"\n                }\n            ]\n        },\n        {\n            \"id\": \"agent.cpu_usage_average\",\n            \"label\": \"CPU Usage\",\n            \"description\": \"Alarm which returns CRITICAL, WARNING or OK based upon average CPU usage\",\n            \"check_type\": \"agent.cpu\",\n            \"criteria\": \"if (metric['usage_average'] > ${critical_threshold}) {\\n  return new AlarmStatus(CRITICAL, 'CPU usage is #{usage_average}%');\\n}\\n\\nif (metric['usage_average'] > ${warning_threshold}) {\\n  return new AlarmStatus(WARNING, 'CPU usage is #{usage_average}%');\\n}\\n\\nreturn new AlarmStatus(OK, 'CPU usage is #{usage_average}%');\\n\",\n            \"fields\": [\n                {\n                    \"name\": \"critical_threshold\",\n                    \"description\": \"CPU usage percentage above which CRITICAL is returned\",\n                    \"type\": \"whole number (may be zero padded)\"\n                },\n                {\n                    \"name\": \"warning_threshold\",\n                    \"description\": \"CPU usage percentage above which WARNING is returned\",\n                    \"type\": \"whole number (may be zero padded)\"\n                }\n            ]\n        },\n        {\n            \"id\": \"agent.memory_usage\",\n            \"label\": \"Memory usage\",\n            \"description\": \"Alarm which returns CRITICAL, WARNING or OK based upon memory usage\",\n            \"check_type\": \"agent.memory\",\n            \"criteria\": \"if (percentage(metric['actual_used'], metric['total']) > 90) {\\n  return new AlarmStatus(CRITICAL, 'Memory usage is above 90%');\\n}\\n\\nif (percentage(metric['actual_used'], metric['total']) > 80) {\\n  return new AlarmStatus(WARNING, 'Memory usage is above 80%');\\n}\\n\\nreturn new AlarmStatus(OK, 'Memory usage is below 80%');\\n\",\n            \"fields\": []\n        },\n        {\n            \"id\": \"agent.filesystem_usage\",\n            \"label\": \"Filesystem usage\",\n            \"description\": \"Alarm which returns CRITICAL, WARNING or OK based upon filesystem usage\",\n            \"check_type\": \"agent.filesystem\",\n            \"criteria\": \"if (percentage(metric['used'], metric['total']) > 90) {\\n  return new AlarmStatus(CRITICAL, 'Disk usage is above 90%');\\n}\\n\\nif (percentage(metric['used'], metric['total']) > 80) {\\n  return new AlarmStatus(WARNING, 'Disk usage is above 80%');\\n}\\n\\nreturn new AlarmStatus(OK, 'Disk usage is below 80%');\\n\",\n            \"fields\": []\n        },\n        {\n            \"id\": \"agent.high_load_average\",\n            \"label\": \"High Load Average\",\n            \"description\": \"Alarm which returns CRITICAL, WARNING or OK based on load average\",\n            \"check_type\": \"agent.load_average\",\n            \"criteria\": \"if (metric['5m'] > ${critical_threshold}) {\\n  return new AlarmStatus(CRITICAL, '5 minute load average is #{5m}');\\n}\\n\\nif (metric['5m'] > ${warning_threshold}) {\\n  return new AlarmStatus(WARNING, '5 minute load average is #{5m}');\\n}\\n\\nreturn new AlarmStatus(OK, '5 minute load average is #{5m}');\\n\",\n            \"fields\": [\n                {\n                    \"name\": \"critical_threshold\",\n                    \"description\": \"Load average above which CRITICAL is returned\",\n                    \"type\": \"whole number (may be zero padded)\"\n                },\n                {\n                    \"name\": \"warning_threshold\",\n                    \"description\": \"Load average above which WARNING is returned\",\n                    \"type\": \"whole number (may be zero padded)\"\n                }\n            ]\n        },\n        {\n            \"id\": \"agent.network_transmit_rate\",\n            \"label\": \"Network transmit rate\",\n            \"description\": \"Alarm which returns CRITICAL, WARNING or OK based upon network transmit rate\",\n            \"check_type\": \"agent.network\",\n            \"criteria\": \"if (rate(metric['tx_bytes']) > ${critical_threshold}) {\\n  return new AlarmStatus(CRITICAL, 'Network receive rate on ${interface} has exceeded ${critical_threshold} bytes/second');\\n}\\n\\nif (rate(metric['tx_bytes']) > ${warning_threshold}) {\\n  return new AlarmStatus(WARNING, 'Network receive rate on ${interface} has exceeded ${warning_threshold} bytes/second');\\n}\\n\\nreturn new AlarmStatus(OK, 'Network transmit rate on ${interface} is less than ${warning_threshold} bytes/second');\\n\",\n            \"fields\": [\n                {\n                    \"name\": \"interface\",\n                    \"description\": \"The network interface to alert on\",\n                    \"type\": \"string\"\n                },\n                {\n                    \"name\": \"critical_threshold\",\n                    \"description\": \"Network transmit rate, in bytes per second, above which CRITICAL is returned\",\n                    \"type\": \"whole number (may be zero padded)\"\n                },\n                {\n                    \"name\": \"warning_threshold\",\n                    \"description\": \"Network transmit rate, in bytes per second, above which WARNING is returned\",\n                    \"type\": \"whole number (may be zero padded)\"\n                }\n            ]\n        },\n        {\n            \"id\": \"agent.network_receive_rate\",\n            \"label\": \"Network receive\",\n            \"description\": \"Alarm which returns CRITICAL, WARNING or OK based upon network receive rate\",\n            \"check_type\": \"agent.network\",\n            \"criteria\": \"if (rate(metric['rx_bytes']) > ${critical_threshold}) {\\n  return new AlarmStatus(CRITICAL, 'Network receive rate on ${interface} has exceeded ${critical_threshold} bytes/second');\\n}\\n\\nif (rate(metric['rx_bytes']) > ${warning_threshold}) {\\n  return new AlarmStatus(WARNING, 'Network receive rate on ${interface} has exceeded ${warning_threshold} bytes/second');\\n}\\n\\nreturn new AlarmStatus(OK, 'Network receive rate on ${interface} is less than ${warning_threshold} bytes/second');\\n\",\n            \"fields\": [\n                {\n                    \"name\": \"interface\",\n                    \"description\": \"The network interface to alert on\",\n                    \"type\": \"string\"\n                },\n                {\n                    \"name\": \"critical_threshold\",\n                    \"description\": \"Network receive rate, in bytes per second, above which CRITICAL is returned\",\n                    \"type\": \"whole number (may be zero padded)\"\n                },\n                {\n                    \"name\": \"warning_threshold\",\n                    \"description\": \"Network receive rate, in bytes per second, above which WARNING is returned\",\n                    \"type\": \"whole number (may be zero padded)\"\n                }\n            ]\n        }\n    ],\n    \"metadata\": {\n        \"count\": 18,\n        \"limit\": null,\n        \"marker\": null,\n        \"next_marker\": null,\n        \"next_href\": null\n    }\n}",
    "headers": {
        "Content-Type": "application/json; charset=UTF-8",
        "Date": "Fri, 19 Jul 2013 18:35:59 GMT",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-LB": "dfw1-maas-prod-api0",
        "X-RateLimit-Limit": "50000",
        "X-RateLimit-Remaining": "49882",
        "X-RateLimit-Type": "global",
        "X-RateLimit-Window": "24 hours",
        "X-Response-Id": ""
    },
    "remote_ip": "127.0.0.1",
    "status": 200
}
